

















Epoch 1/7:  21%|█████████████████████▋                                                                                  | 428/2050 [00:37<02:23, 11.31img/s, loss (batch)=0.376]
Traceback (most recent call last):
  File "d:\UBB\CVDL\Project\train.py", line 107, in <module>
    main()
  File "d:\UBB\CVDL\Project\train.py", line 103, in main
    train_model(dataset,model,device,epochs=7)
  File "d:\UBB\CVDL\Project\train.py", line 63, in train_model
    for batch in train_loader:
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 49, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 364, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\utils\data\dataset.py", line 364, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "d:\UBB\CVDL\Project\dataset\LFWDataset.py", line 100, in __getitem__
    item=(self._transforms(item[0]),self._transforms(item[1]))
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\v2\_container.py", line 53, in forward
    outputs = transform(*inputs)
              ^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\v2\_transform.py", line 50, in forward
    flat_outputs = [
                   ^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\v2\_transform.py", line 51, in <listcomp>
    self._transform(inpt, params) if needs_transform else inpt
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\v2\_deprecated.py", line 50, in _transform
    return _F.to_tensor(inpt)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\denis\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\transforms\functional.py", line 155, in to_tensor
    return img.to(dtype=default_float_dtype).div(255)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt